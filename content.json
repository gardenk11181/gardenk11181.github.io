{"meta":{"title":"Garden","subtitle":"","description":"","author":"Jeongwon Kim","url":"https://gardenk11181.github.io","root":"/"},"pages":[],"posts":[{"title":"DCGAN - (3) Training","slug":"dcgan-03","date":"2021-06-30T01:33:35.000Z","updated":"2021-06-30T03:26:39.852Z","comments":true,"path":"2021/06/30/dcgan-03/","link":"","permalink":"https://gardenk11181.github.io/2021/06/30/dcgan-03/","excerpt":"","text":"Previous Article: DCGAN - (2) Architecture 이번 글에서는 DCGAN의 학습과정을 다뤄보자. 지금까지 그래왔듯이 pytorch구현을 위한 기술적인 부분은 미뤄두고, 개념만 다뤄볼 것이다. 기본적으로 Stochastic Gradient Descent(SGD)방법을 기반으로 하는 Adam Optimizer를 사용한다. SGD방법은 일반적인 Gradient Descent 방법과는 다르게 모든 데이터의 loss 값을 이용하지 않고 미리 정해둔 mini-batch 크기만큼 랜덤하게 추출한 데이터만을 가지고 진행하는 방법이다. 이렇게 확률적으로 진행되기 때문에 Stochastic이라는 명칭이 붙었다. Adam Optimizer에 대한 자세한 내용은 논문을 좀 더 공부한 후 적어보도록 하겠다. I. Initialization각 layer의 초기 weight들은 identically independent하게 을 따르는 값들로 설정하였고, LeakyReLU의 기울기는 0.2로 설정하였다. II. Train DiscriminatorDiscriminator는 주어진 image를 정확히 예측하는 것이 목표이다. 즉, 을 maximize하는 것이 목표이다. 리를 위하여 다음과 같은 과정을 따른다. mini-batch 크기만큼의 real 학습 데이터를 Discriminator에 넣어 loss 값을 구하고, backward로 Discriminator의 gradient를 구한다. mini-batch 크기만큼의 fake 데이터를 현재 Generator에서 생성하고, 이를 Discriminator에 넣어 loss 값을 구한다. 이후 마찬가지로 backward로 Discriminator의 gradient를 구한다. 1과 2에 의해 구해진 각 weight들에 대한 gradient의 평균을 가지고 Adam Optimizer를 통해 Discriminator의 parameter를 update한다. III. Train GeneratorGenerator는 real같은 fake image를 만드는 것이 목표이기에 를 minimize하는 방향으로 학습해야 한다. 그러나 논문에 따르면 이 방법이 학습 초기에 충분한 gradient를 제공하지 못한다고 한다. 따라서 pytorch에서는 이를 대신하여 를 maximize하는 방향으로 학습하였다. 이는 fake image를 fake로 인식하지 않는 방향으로 학습한다고 해석할 수 있기에 직관적으로 타당하다고 여겨진다. Discriminator 학습 시에 생성했던 fake images를 현재의 Discriminator에 넣어 loss 룰 구하고, backward로 Generator의 gradient를 구한다. 구한 gradient를 가지고 Adam Optimizer를 통해 Generator의 parameter를 update한다. 아래 그림은 pytorch에서 celeba데이터에 대하여 위와 같은 방법으로 학습시켰을 때의 Loss값의 변화를 나타낸 그래프이다. 최종적으로 1600여 데이터를 5번의 epoch로 학습시켰을 때, Real Image로 부터 얻어진 Fake Image는 다음과 같이 나온다고 한다. 이제 DCGAN구현을 위한 대략적인 공부는 마친 것 같다. 다음 글에서부터는 MNIST데이터를 가지고 DCGAN을 구현해보고 학습시켜보도록 하자.","categories":[{"name":"AI","slug":"AI","permalink":"https://gardenk11181.github.io/categories/AI/"},{"name":"DCGAN","slug":"AI/DCGAN","permalink":"https://gardenk11181.github.io/categories/AI/DCGAN/"}],"tags":[{"name":"ai","slug":"ai","permalink":"https://gardenk11181.github.io/tags/ai/"},{"name":"deep learning","slug":"deep-learning","permalink":"https://gardenk11181.github.io/tags/deep-learning/"},{"name":"gan","slug":"gan","permalink":"https://gardenk11181.github.io/tags/gan/"}]},{"title":"DCGAN - (2) Architecture","slug":"dcgan-02","date":"2021-06-29T04:06:09.000Z","updated":"2021-06-30T03:21:26.057Z","comments":true,"path":"2021/06/29/dcgan-02/","link":"","permalink":"https://gardenk11181.github.io/2021/06/29/dcgan-02/","excerpt":"","text":"Previous Article: DCGAN - (1) Generative Adversarial Networks 이번 글에서는 DCGAN이 어떠한 Architecture을 가지는지 알아보자. 기본적으로는 Deep Neural Network의 한 종류인 CNN(Convolutional Neural Network)의 구조를 가진다. DCGAN의 CNN은 Convolutional layer와 Batch-norm layer, 그리고 ReLU로 이루어져 있는데 각 layer와 CNN에 대한 자세한 설명은 다음 기회에 해보도록 하고, 본 글에서는 이들이 DCGAN에서 어떻게 구성되어 있는지만 알아보도록 하자. Generator 위 그림과 같이 Generator는 latent vector를 image로 mapping함에 있어 총 네개의 convolutional layer로 이루어진 CNN 구조를 사용한다. 주어진 latent vector를 첫번째 activation map으로 reshape하는 layer까지 합하면 총 5개이다. 다만, Generator에서는 일반적인 convolutional layer가 아닌 convolutional transpose layer를 사용한다. 일반적인 convolutional layer는 큰 size의 input data를 작은 output data로 mapping하지만, conv-transpose layer는 input data의 size보다 output data의 size가 더 크다는 근본적인 차이점이 있다. 자세한 내용은 역시 CNN관련 글에서 알아보도록 하자. DiscriminatorDiscriminator는 Generator의 역순이라고 생각하면 좋다. 즉, 주어진 image를 CNN을 통해 scala probability로 mapping한다. 마찬가지로 총 네개의 convolutional layer가 사용되는데, Discriminator는 점차 차원을 줄여나가기에 일반적인 convolutional layer를 사용한다. 또한, 일반적인 ReLU function을 사용하지 않고 위 그림과 같이 에서의 기울기가 0이 아닌 작은 양의 값을 가지는 LeakyReLU function을 사용하였다. 지금까지 아주 간단하게 DCGAN의 Architecture를 알아보았고, 다음 글에서는 이 모델을 어떻게 학습시키는지 알아보자. Next Article: DCGAN - (3) Training","categories":[{"name":"AI","slug":"AI","permalink":"https://gardenk11181.github.io/categories/AI/"},{"name":"DCGAN","slug":"AI/DCGAN","permalink":"https://gardenk11181.github.io/categories/AI/DCGAN/"}],"tags":[{"name":"ai","slug":"ai","permalink":"https://gardenk11181.github.io/tags/ai/"},{"name":"deep learning","slug":"deep-learning","permalink":"https://gardenk11181.github.io/tags/deep-learning/"},{"name":"gan","slug":"gan","permalink":"https://gardenk11181.github.io/tags/gan/"}]},{"title":"DCGAN - (1) Generative Adversarial Networks","slug":"dcgan-01","date":"2021-06-27T03:46:33.000Z","updated":"2021-06-30T03:21:11.933Z","comments":true,"path":"2021/06/27/dcgan-01/","link":"","permalink":"https://gardenk11181.github.io/2021/06/27/dcgan-01/","excerpt":"","text":"인턴 1주차 목표는 pytorch가 제공하는 DCGAN tutorial을 공부해오는 것이었다. 디테일한 코드보다는 용어의 의미와 전체적인 흐름 및 이론에 주목하여 살펴보도록 하자. GAN (Generative Adversarial Networks)먼저, GAN이란 Generator와 Discriminator로 이루어진 Adversarial Networks로, 주어진 data의 분포와 비슷한 분포의 sample을 추출하고자 하는 generative model이다. 여기서 ‘Adversarial(적대적)’이라 표현한 이유는, 후술하겠지만 Generator와 Discriminator가 서로 mini-max게임을 하는 관계이기 때문이다. Generator는 latent vector를 가지고 fake image를 만들고, Discriminator는 주어진 image가 real인지 아닌지를 판별한다. 즉, Discriminator는 주어진 image가 real인지 아닌지 정확하게 분류하고자 하는 것이 목표이고, Generator는 이러한 Discriminator가 자기가 만든 fake image를 real image로 인식하게끔 하는 것이 목표이다. 이러한 이유로 Adversarial Networks라고 표현하였다. Loss Function앞서 말한 GAN의 의미를 이해한다면, 다음과 같이 정의된 Loss Function은 꽤나 자연스럽게 다가온다. Discriminator는 training data\b x를 real로, Generator에 의해 생성된 G(z)를 fake로 분류할 확률을 maximize한다. 이와 동시에 Generator는 Discriminator가 G(z)를 fake로 분류할 확률을 minimize한다. GAN을 제시한 논문에 따르면 두 분포 가 같을 때가 본 mini-max game의 solution이지만, 수렴조건에 관한 부분은 아직 연구중에 있다고 한다. DCGAN은 이러한 GAN을 Deep Convolutional Architecture를 가지고 구현한 모델에 해당한다. 자세한 내용은 다음 글에서 다뤄보자. Next Article: DCGAN - (2) Architecture","categories":[{"name":"AI","slug":"AI","permalink":"https://gardenk11181.github.io/categories/AI/"},{"name":"DCGAN","slug":"AI/DCGAN","permalink":"https://gardenk11181.github.io/categories/AI/DCGAN/"}],"tags":[{"name":"ai","slug":"ai","permalink":"https://gardenk11181.github.io/tags/ai/"},{"name":"deep learning","slug":"deep-learning","permalink":"https://gardenk11181.github.io/tags/deep-learning/"},{"name":"gan","slug":"gan","permalink":"https://gardenk11181.github.io/tags/gan/"}]}],"categories":[{"name":"AI","slug":"AI","permalink":"https://gardenk11181.github.io/categories/AI/"},{"name":"DCGAN","slug":"AI/DCGAN","permalink":"https://gardenk11181.github.io/categories/AI/DCGAN/"}],"tags":[{"name":"ai","slug":"ai","permalink":"https://gardenk11181.github.io/tags/ai/"},{"name":"deep learning","slug":"deep-learning","permalink":"https://gardenk11181.github.io/tags/deep-learning/"},{"name":"gan","slug":"gan","permalink":"https://gardenk11181.github.io/tags/gan/"}]}