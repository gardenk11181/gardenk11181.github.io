{"meta":{"title":"Garden","subtitle":"","description":"","author":"Jeongwon Kim","url":"https://gardenk11181.github.io","root":"/"},"pages":[],"posts":[{"title":"DCGAN - (5) Discriminator 구현 및 학습 결과","slug":"dcgan-05","date":"2021-07-06T02:50:33.000Z","updated":"2021-07-07T07:51:56.862Z","comments":true,"path":"2021/07/06/dcgan-05/","link":"","permalink":"https://gardenk11181.github.io/2021/07/06/dcgan-05/","excerpt":"","text":"Previous Article: DCGAN - (4) Generator 구현 tensorflow tutorial에서 제시하는 Discriminator Architecture는 좀 더 간단하며, 총 세가지의 layer로 이루어져 있다. Generator와 다르게 크기를 줄여나가야 하므로 일반적인 convolutional layer를 사용한다. tensorflow에서의 code는 아래와 같다. 123456789101112131415def make_discriminator_model(): model = tf.keras.Sequential() model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding=&#x27;same&#x27;, input_shape=[28, 28, 1])) model.add(layers.LeakyReLU()) model.add(layers.Dropout(0.3)) model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding=&#x27;same&#x27;)) model.add(layers.LeakyReLU()) model.add(layers.Dropout(0.3)) model.add(layers.Flatten()) model.add(layers.Dense(1)) return model 위 코드를 pytorch에서 구현해보자. 첫번째 layer에서는 28X28X1 image를 14X14X64 feature maps로 만든다. 이 때, parameter는 in_channel: 1, out_channel: 64, kernel_size: 5, stride: 2, padding: 2을 사용한다. 두번째 layer에서는 14X14X64 feature maps를 다시 7X7X128 feature maps로 만든다. parameter는 마찬가지로 in_channel: 64, out_channel: 128, kernel_size: 5, stride: 2, padding: 2을 사용한다. 마지막 layer에서는 7X7X128 feature maps를 scala로 만든다. 이 때, tensorflow에서는 Flatten 이후에 Dense(1)로 지정하면 바로 scala로 mapping해주지만, pytorch에서는 Flatten했을 때의 node 개수를 Linear(node,1)의 형태로 지정해줘야 한다. 구현한 pytorch 코드는 아래와 같다. 12345678910111213141516171819class Discriminator(nn.Module): def __init__(self, ngpu): super(Discriminator, self).__init__() self.ngpu = ngpu self.main = nn.Sequential( nn.Conv2d(1,64,5,2,2,bias=False), nn.LeakyReLU(0.3,True), nn.Dropout2d(0.3), nn.Conv2d(64,128,5,2,2,bias=False), nn.LeakyReLU(0.3,True), nn.Dropout2d(0.3), nn.Flatten(), nn.Linear(6272,1), nn.Sigmoid() ) def forward(self, input): return self.main(input) 이렇게 설정을 마친 후에 학습을 진행하게 되면 다음과 같은 images가 생성됨을 확인할 수 있었다.","categories":[{"name":"AI","slug":"AI","permalink":"https://gardenk11181.github.io/categories/AI/"},{"name":"DCGAN","slug":"AI/DCGAN","permalink":"https://gardenk11181.github.io/categories/AI/DCGAN/"}],"tags":[{"name":"ai","slug":"ai","permalink":"https://gardenk11181.github.io/tags/ai/"},{"name":"deep learning","slug":"deep-learning","permalink":"https://gardenk11181.github.io/tags/deep-learning/"},{"name":"gan","slug":"gan","permalink":"https://gardenk11181.github.io/tags/gan/"}]},{"title":"DCGAN - (4) Generator 구현","slug":"dcgan-04","date":"2021-07-02T01:00:00.000Z","updated":"2021-07-07T07:07:26.526Z","comments":true,"path":"2021/07/02/dcgan-04/","link":"","permalink":"https://gardenk11181.github.io/2021/07/02/dcgan-04/","excerpt":"","text":"Previous Article: DCGAN - (3) Architecture pytorch tutorial에서 제시한 celebA데이터의 경우에는 크기가 제법 되기에 1차적인 목표는 MNIST 데이터를 통해 구현해보는 것이다. MNIST data를 pytorch로 가져오는 방법은 여기, MNIST data에 대한 DCGAN model은 여기에 나와있다. Architecture 구성을 제외한 모든 과정은 pytorch tutorial과 동일하게 진행하면 되기에 두 모델을 설정하는 부분만 살펴보고, 나머지는 깃허브 링크로 남겨두겠다. 위 링크에서 다룬 tensorflow tutorial에서의 Generator network는 아래와 같다. 1234567891011121314151617181920212223def make_generator_model(): model = tf.keras.Sequential() model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,))) model.add(layers.BatchNormalization()) model.add(layers.LeakyReLU()) model.add(layers.Reshape((7, 7, 256))) assert model.output_shape == (None, 7, 7, 256) # 주목: 배치사이즈로 None이 주어집니다. model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding=&#x27;same&#x27;, use_bias=False)) assert model.output_shape == (None, 7, 7, 128) model.add(layers.BatchNormalization()) model.add(layers.LeakyReLU()) model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding=&#x27;same&#x27;, use_bias=False)) assert model.output_shape == (None, 14, 14, 64) model.add(layers.BatchNormalization()) model.add(layers.LeakyReLU()) model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding=&#x27;same&#x27;, use_bias=False, activation=&#x27;tanh&#x27;)) assert model.output_shape == (None, 28, 28, 1) return model 총 네가지의 layer로 이루어져 있음을 알 수 있다. 첫번째 layer에서는 100X1 latent vector로 7X7X256의 feature maps을 만든다. 위에서는 dense layer를 통해 총 7X7X256개의 node를 만들고 reshape을 했지만, 우리는 pytorch tutorial에서 사용한 방법과 동일하게 convolutional layer를 이용할 것이다. 이 때, in_channel: 100, out_channel: 256, kernel size: 7, stride: 1의 convolutional transpose layer를 이용한다. pytorch는 tensorflow처럼 output shape의 크기에 맞게 알아서 padding을 넣어주지 않기 때문에 직접 padding 값을 계산해야 한다. 이는 convolutional layer의 원리에 대한 이해가 필요하다. (조만간 자세하게 다루는 글을 작성할 것이다.) 두번째 layer에서는 in_channel: 256, out_channel: 128, kernel size: 5, stride: 1, padding: 2의 convolutional transpose layer를 이용하여 7X7X128 feature maps을 만든다. 세번째 layer에서는 위 모델과 조금 다르게 진행할 수밖에 없었다. pytorch에서 Conv2DTranspose layer의 원리 상, stride가 2이고 kernel size가 홀수일 때 width와 height이 짝수인 feature map을 만들지 못한다. 이는 tensorflow와 달리 pytorch에서는 asymmetric padding을 주지 못하기 때문이다. 따라서 kernel size 5는 유지하되, output_padding을 1만큼 줌으로써 절충하였다. 즉, in_channel: 128, out_channel: 64, kernel size: 5, stride: 2, padding: 2, output_padding: 1의 convolutional transpose layer를 이용하여 14X14X64 feature maps을 만들었다. 마지막 layer에서도 마찬가지 이유로 in_channel: 64, out_channel: 1, kernel size: 5, stride: 2, padding: 2, output_padding: 1의 convolutional transpose layer를 이용하여 28X28X1 feature maps(fake image)를 만들었다. 최종 코드는 아래와 같다. 12345678910111213141516171819202122class Generator(nn.Module): def __init__(self, ngpu): super(Generator, self).__init__() self.ngpu = ngpu self.main = nn.Sequential( nn.ConvTranspose2d(100,256,7,1,0,bias=False), nn.BatchNorm2d(256), nn.LeakyReLU(True), nn.ConvTranspose2d(256,128,5,1,2,bias=False), nn.BatchNorm2d(128), nn.LeakyReLU(True), nn.ConvTranspose2d(128,64,4,2,1,bias=False), nn.BatchNorm2d(64), nn.LeakyReLU(True), nn.ConvTranspose2d(64,1,4,2,1,bias=False), nn.Tanh() ) def forward(self, input): return self.main(input) 어쩌다 보니 글이 길어졌기에, Discriminator network와 학습결과는 다음 글에서 이어나가도록 하겠다. Next Article: DCGAN - (5) Descriminator 구현 및 학습 결과","categories":[{"name":"AI","slug":"AI","permalink":"https://gardenk11181.github.io/categories/AI/"},{"name":"DCGAN","slug":"AI/DCGAN","permalink":"https://gardenk11181.github.io/categories/AI/DCGAN/"}],"tags":[{"name":"ai","slug":"ai","permalink":"https://gardenk11181.github.io/tags/ai/"},{"name":"deep learning","slug":"deep-learning","permalink":"https://gardenk11181.github.io/tags/deep-learning/"},{"name":"gan","slug":"gan","permalink":"https://gardenk11181.github.io/tags/gan/"}]},{"title":"DCGAN - (3) Training","slug":"dcgan-03","date":"2021-06-30T01:33:35.000Z","updated":"2021-07-02T07:36:02.070Z","comments":true,"path":"2021/06/30/dcgan-03/","link":"","permalink":"https://gardenk11181.github.io/2021/06/30/dcgan-03/","excerpt":"","text":"Previous Article: DCGAN - (2) Architecture 이번 글에서는 DCGAN의 학습과정을 다뤄보자. 지금까지 그래왔듯이 pytorch구현을 위한 기술적인 부분은 미뤄두고, 개념만 다뤄볼 것이다. 기본적으로 Stochastic Gradient Descent(SGD)방법을 기반으로 하는 Adam Optimizer를 사용한다. SGD방법은 일반적인 Gradient Descent 방법과는 다르게 모든 데이터의 loss 값을 이용하지 않고 미리 정해둔 mini-batch 크기만큼 랜덤하게 추출한 데이터만을 가지고 진행하는 방법이다. 이렇게 확률적으로 진행되기 때문에 Stochastic이라는 명칭이 붙었다. Adam Optimizer에 대한 자세한 내용은 논문을 좀 더 공부한 후 적어보도록 하겠다. I. Initialization각 layer의 초기 weight들은 identically independent하게 을 따르는 값들로 설정하였고, LeakyReLU의 기울기는 0.2로 설정하였다. II. Train DiscriminatorDiscriminator는 주어진 image를 정확히 예측하는 것이 목표이다. 즉, 을 maximize하는 것이 목표이다. 리를 위하여 다음과 같은 과정을 따른다. mini-batch 크기만큼의 real 학습 데이터를 Discriminator에 넣어 loss 값을 구하고, backward로 Discriminator의 gradient를 구한다. mini-batch 크기만큼의 fake 데이터를 현재 Generator에서 생성하고, 이를 Discriminator에 넣어 loss 값을 구한다. 이후 마찬가지로 backward로 Discriminator의 gradient를 구한다. 1과 2에 의해 구해진 각 weight들에 대한 gradient의 평균을 가지고 Adam Optimizer를 통해 Discriminator의 parameter를 update한다. III. Train GeneratorGenerator는 real같은 fake image를 만드는 것이 목표이기에 를 minimize하는 방향으로 학습해야 한다. 그러나 논문에 따르면 이 방법이 학습 초기에 충분한 gradient를 제공하지 못한다고 한다. 따라서 pytorch에서는 이를 대신하여 를 maximize하는 방향으로 학습하였다. 이는 fake image를 fake로 인식하지 않는 방향으로 학습한다고 해석할 수 있기에 직관적으로 타당하다고 여겨진다. Discriminator 학습 시에 생성했던 fake images를 현재의 Discriminator에 넣어 loss 룰 구하고, backward로 Generator의 gradient를 구한다. 구한 gradient를 가지고 Adam Optimizer를 통해 Generator의 parameter를 update한다. 아래 그림은 pytorch에서 celeba데이터에 대하여 위와 같은 방법으로 학습시켰을 때의 Loss값의 변화를 나타낸 그래프이다. 최종적으로 1600여 데이터를 5번의 epoch로 학습시켰을 때, Real Image로 부터 얻어진 Fake Image는 다음과 같이 나온다고 한다. 이제 DCGAN구현을 위한 대략적인 공부는 마친 것 같다. 다음 글에서부터는 MNIST데이터를 가지고 DCGAN을 구현해보고 학습시켜보도록 하자. Next Article: DCGAN - (4) Implementation of Network for Generator","categories":[{"name":"AI","slug":"AI","permalink":"https://gardenk11181.github.io/categories/AI/"},{"name":"DCGAN","slug":"AI/DCGAN","permalink":"https://gardenk11181.github.io/categories/AI/DCGAN/"}],"tags":[{"name":"ai","slug":"ai","permalink":"https://gardenk11181.github.io/tags/ai/"},{"name":"deep learning","slug":"deep-learning","permalink":"https://gardenk11181.github.io/tags/deep-learning/"},{"name":"gan","slug":"gan","permalink":"https://gardenk11181.github.io/tags/gan/"}]},{"title":"DCGAN - (2) Architecture","slug":"dcgan-02","date":"2021-06-29T04:06:09.000Z","updated":"2021-06-30T03:21:26.057Z","comments":true,"path":"2021/06/29/dcgan-02/","link":"","permalink":"https://gardenk11181.github.io/2021/06/29/dcgan-02/","excerpt":"","text":"Previous Article: DCGAN - (1) Generative Adversarial Networks 이번 글에서는 DCGAN이 어떠한 Architecture을 가지는지 알아보자. 기본적으로는 Deep Neural Network의 한 종류인 CNN(Convolutional Neural Network)의 구조를 가진다. DCGAN의 CNN은 Convolutional layer와 Batch-norm layer, 그리고 ReLU로 이루어져 있는데 각 layer와 CNN에 대한 자세한 설명은 다음 기회에 해보도록 하고, 본 글에서는 이들이 DCGAN에서 어떻게 구성되어 있는지만 알아보도록 하자. Generator 위 그림과 같이 Generator는 latent vector를 image로 mapping함에 있어 총 네개의 convolutional layer로 이루어진 CNN 구조를 사용한다. 주어진 latent vector를 첫번째 activation map으로 reshape하는 layer까지 합하면 총 5개이다. 다만, Generator에서는 일반적인 convolutional layer가 아닌 convolutional transpose layer를 사용한다. 일반적인 convolutional layer는 큰 size의 input data를 작은 output data로 mapping하지만, conv-transpose layer는 input data의 size보다 output data의 size가 더 크다는 근본적인 차이점이 있다. 자세한 내용은 역시 CNN관련 글에서 알아보도록 하자. DiscriminatorDiscriminator는 Generator의 역순이라고 생각하면 좋다. 즉, 주어진 image를 CNN을 통해 scala probability로 mapping한다. 마찬가지로 총 네개의 convolutional layer가 사용되는데, Discriminator는 점차 차원을 줄여나가기에 일반적인 convolutional layer를 사용한다. 또한, 일반적인 ReLU function을 사용하지 않고 위 그림과 같이 에서의 기울기가 0이 아닌 작은 양의 값을 가지는 LeakyReLU function을 사용하였다. 지금까지 아주 간단하게 DCGAN의 Architecture를 알아보았고, 다음 글에서는 이 모델을 어떻게 학습시키는지 알아보자. Next Article: DCGAN - (3) Training","categories":[{"name":"AI","slug":"AI","permalink":"https://gardenk11181.github.io/categories/AI/"},{"name":"DCGAN","slug":"AI/DCGAN","permalink":"https://gardenk11181.github.io/categories/AI/DCGAN/"}],"tags":[{"name":"ai","slug":"ai","permalink":"https://gardenk11181.github.io/tags/ai/"},{"name":"deep learning","slug":"deep-learning","permalink":"https://gardenk11181.github.io/tags/deep-learning/"},{"name":"gan","slug":"gan","permalink":"https://gardenk11181.github.io/tags/gan/"}]},{"title":"DCGAN - (1) Generative Adversarial Networks","slug":"dcgan-01","date":"2021-06-27T03:46:33.000Z","updated":"2021-06-30T03:21:11.933Z","comments":true,"path":"2021/06/27/dcgan-01/","link":"","permalink":"https://gardenk11181.github.io/2021/06/27/dcgan-01/","excerpt":"","text":"인턴 1주차 목표는 pytorch가 제공하는 DCGAN tutorial을 공부해오는 것이었다. 디테일한 코드보다는 용어의 의미와 전체적인 흐름 및 이론에 주목하여 살펴보도록 하자. GAN (Generative Adversarial Networks)먼저, GAN이란 Generator와 Discriminator로 이루어진 Adversarial Networks로, 주어진 data의 분포와 비슷한 분포의 sample을 추출하고자 하는 generative model이다. 여기서 ‘Adversarial(적대적)’이라 표현한 이유는, 후술하겠지만 Generator와 Discriminator가 서로 mini-max게임을 하는 관계이기 때문이다. Generator는 latent vector를 가지고 fake image를 만들고, Discriminator는 주어진 image가 real인지 아닌지를 판별한다. 즉, Discriminator는 주어진 image가 real인지 아닌지 정확하게 분류하고자 하는 것이 목표이고, Generator는 이러한 Discriminator가 자기가 만든 fake image를 real image로 인식하게끔 하는 것이 목표이다. 이러한 이유로 Adversarial Networks라고 표현하였다. Loss Function앞서 말한 GAN의 의미를 이해한다면, 다음과 같이 정의된 Loss Function은 꽤나 자연스럽게 다가온다. Discriminator는 training data\b x를 real로, Generator에 의해 생성된 G(z)를 fake로 분류할 확률을 maximize한다. 이와 동시에 Generator는 Discriminator가 G(z)를 fake로 분류할 확률을 minimize한다. GAN을 제시한 논문에 따르면 두 분포 가 같을 때가 본 mini-max game의 solution이지만, 수렴조건에 관한 부분은 아직 연구중에 있다고 한다. DCGAN은 이러한 GAN을 Deep Convolutional Architecture를 가지고 구현한 모델에 해당한다. 자세한 내용은 다음 글에서 다뤄보자. Next Article: DCGAN - (2) Architecture","categories":[{"name":"AI","slug":"AI","permalink":"https://gardenk11181.github.io/categories/AI/"},{"name":"DCGAN","slug":"AI/DCGAN","permalink":"https://gardenk11181.github.io/categories/AI/DCGAN/"}],"tags":[{"name":"ai","slug":"ai","permalink":"https://gardenk11181.github.io/tags/ai/"},{"name":"deep learning","slug":"deep-learning","permalink":"https://gardenk11181.github.io/tags/deep-learning/"},{"name":"gan","slug":"gan","permalink":"https://gardenk11181.github.io/tags/gan/"}]}],"categories":[{"name":"AI","slug":"AI","permalink":"https://gardenk11181.github.io/categories/AI/"},{"name":"DCGAN","slug":"AI/DCGAN","permalink":"https://gardenk11181.github.io/categories/AI/DCGAN/"}],"tags":[{"name":"ai","slug":"ai","permalink":"https://gardenk11181.github.io/tags/ai/"},{"name":"deep learning","slug":"deep-learning","permalink":"https://gardenk11181.github.io/tags/deep-learning/"},{"name":"gan","slug":"gan","permalink":"https://gardenk11181.github.io/tags/gan/"}]}